# ğŸš€ Hand Gesture Interaction System with Extended Kalman Filter (EKF)
### Realâ€‘time Hand Tracking â€¢ Gesture Recognition â€¢ Air Drawing â€¢ Virtual Mouse â€¢ Volume Control

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![OpenCV](https://img.shields.io/badge/OpenCV-4.8.1.78-success)
![MediaPipe](https://img.shields.io/badge/MediaPipe-0.10.8-orange)
![NumPy](https://img.shields.io/badge/NumPy-1.24.3-informational)
![SciPy](https://img.shields.io/badge/SciPy-1.11.4-informational)

A modular **Computer Vision + Humanâ€‘Computer Interaction (HCI)** project that transforms hand movements into touchless control.
The system tracks **3D hand landmarks** in real time, recognizes gestures, and stabilizes motion using an **Adaptive Extended Kalman Filter (EKF)** for smooth and reliable interaction.

---

## âœ¨ Features

- ğŸ–± **Virtual Mouse** â€” Smooth cursor control, click/drag, and twoâ€‘finger scrolling  
- ğŸ¨ **Air Drawing** â€” Realâ€‘time drawing with gesture-based canvas interaction  
- ğŸ”Š **Volume Control** â€” Pinch distance mapped to system volume (Linux support via `amixer`)  
- âœ‹ **Gesture Recognition** â€” Static and dynamic gesture detection with temporal smoothing  
- ğŸ“‰ **Adaptive EKF Stabilization** â€” Reduces jitter and improves interaction stability  
- ğŸ§© **Modular Mode Architecture** â€” Easily extendable interaction modes  

---

## ğŸ§  System Architecture

Pipeline Overview:

Camera â†’ HandTracker â†’ ThreadedPipeline â†’ GestureRecognizer â†’ Mode â†’ Controller â†’ OS

### Core Components

- **HandTracker (`hand_tracker.py`)**
  - Extracts 21 MediaPipe landmarks
  - Applies Adaptive Extended Kalman Filter for smoothing
  - Computes pinch distance and motion metrics

- **GestureRecognizer (`gesture_recognizer.py`)**
  - Classifies gestures from landmark geometry
  - Applies temporal voting for robustness
  - Filters gestures by active mode

- **Modes (`modes/`)**
  - `mouse_mode.py` â€” Virtual mouse interaction
  - `draw_mode.py` â€” Air drawing system
  - `volume_mode.py` â€” Volume control logic
  - `demo_mode.py` â€” Visualization mode (no side effects)
  - `base.py` â€” Shared mode interface

- **Controllers (`controllers.py`)**
  - Executes OS-level actions (mouse, scrolling, volume)

- **Orchestrator (`core/orchestrator.py`)**
  - Main runtime loop
  - Mode switching
  - Frame rendering

- **Threaded Pipeline (`pipeline/threaded_pipeline.py`)**
  - Separates capture and processing threads for stable latency

---

## ğŸ® Keyboard Shortcuts (Inside OpenCV Window)

| Key | Action |
|---:|---|
| `m` | Mouse mode |
| `d` | Draw mode |
| `v` | Volume mode |
| `Space` | Demo mode |
| `c` | Clear canvas (Draw mode) |
| `q` | Quit |

---

## âœ‹ Supported Gestures

### Static Gestures
- `Point`
- `Thumbs_Up`
- `Peace`
- `OK`
- `Fist`
- `Open_Palm`

### Pinch Gestures
- `Pinch_TI` (Thumbâ€“Index)
- `Pinch_TM` (Thumbâ€“Middle)

### Dynamic Gestures
- `TwoFinger_Scroll_Up`
- `TwoFinger_Scroll_Down`
- `Swipe_Left`
- `Swipe_Right`
- `Swipe_Up`
- `Swipe_Down`

Gesture handling includes contextual filtering depending on the active mode.

---

## ğŸ“¦ Installation

### 1) Clone the repository
```bash
git clone <YOUR_REPO_URL>
cd hand-tracking-3d
```

### 2) Create a virtual environment

**Windows**
```bash
python -m venv .venv
.venv\Scripts\activate
```

**macOS / Linux**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3) Install dependencies
```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Run the Project

```bash
python main.py
```

A camera window will open. Use keyboard shortcuts to switch modes.

---

## ğŸ”Š Volume Control Notes

Volume control is implemented using:

```
amixer set Master <N>%
```

- Fully supported on Linux systems with `amixer` installed  
- On Windows/macOS, the visual indicator updates but system volume may not change  

---

## ğŸ§ª Running Tests

```bash
python -m pytest -q
```

Unit tests are located in:

```
tests/test_gesture_recognizer.py
```

---

## ğŸ“ Project Structure

```
hand-tracking-3d/
â”œâ”€â”€ main.py
â”œâ”€â”€ app.py
â”œâ”€â”€ gui.py
â”œâ”€â”€ hand_tracker.py
â”œâ”€â”€ gesture_recognizer.py
â”œâ”€â”€ controllers.py
â”œâ”€â”€ constants.py
â”œâ”€â”€ utils.py
â”œâ”€â”€ camera_diag.py
â”œâ”€â”€ hand_model_demo.py
â”‚
â”œâ”€â”€ core/
â”‚   â””â”€â”€ orchestrator.py
â”‚
â”œâ”€â”€ pipeline/
â”‚   â””â”€â”€ threaded_pipeline.py
â”‚
â”œâ”€â”€ modes/
â”‚   â”œâ”€â”€ base.py
â”‚   â”œâ”€â”€ mouse_mode.py
â”‚   â”œâ”€â”€ draw_mode.py
â”‚   â”œâ”€â”€ volume_mode.py
â”‚   â””â”€â”€ demo_mode.py
â”‚
â””â”€â”€ tests/
    â””â”€â”€ test_gesture_recognizer.py
```

