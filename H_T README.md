# ğŸš€ Hand Gesture Interaction System with Extended Kalman Filter

A modular, real-time 3D hand tracking and gesture-based human--computer
interaction framework built using computer vision and probabilistic
filtering techniques.

This system enables touchless interaction through:

-   ğŸ–± Virtual Mouse Control\
-   ğŸ¨ Air Drawing\
-   ğŸ”Š Volume Control (Linux support via amixer)\
-   âœ‹ Real-time Gesture Recognition\
-   ğŸ“ Extended Kalman Filter (EKF) Motion Stabilization\
-   ğŸ§© Modular Mode-Based Architecture

------------------------------------------------------------------------

## ğŸ“Œ Overview

This project implements a real-time hand tracking and gesture
interaction system designed with a research-oriented, modular
architecture.

The system integrates:

-   Landmark-based hand tracking\
-   Geometric gesture recognition\
-   Extended Kalman Filtering for jitter reduction\
-   Mode-based behavior abstraction\
-   OS-level control through controller interfaces

The architecture emphasizes scalability, clarity, and separation of
concerns.

------------------------------------------------------------------------

## ğŸ— System Architecture

Pipeline Overview:

Camera â†’ Hand Tracker â†’ Processing Pipeline â†’ EKF â†’ Gesture Recognizer â†’
Mode â†’ Controller â†’ OS

### Layers

**Tracking Layer** - Extracts hand landmarks - Computes pinch distance -
Normalizes coordinates

**Filtering Layer** - Applies Extended Kalman Filter to smooth landmark
motion - Reduces jitter and improves interaction stability

**Gesture Layer** - Detects finger states - Recognizes pinch gestures -
Interprets interaction patterns

**Mode Layer** - Defines interaction behavior (Mouse, Draw, Volume,
Demo)

**Controller Layer** - Executes OS-level commands (mouse movement,
clicks, volume)

------------------------------------------------------------------------

## ğŸ“‚ Project Structure

    hand-tracking-3d/
    â”‚
    â”œâ”€â”€ main.py
    â”œâ”€â”€ app.py
    â”œâ”€â”€ gui.py
    â”œâ”€â”€ constants.py
    â”œâ”€â”€ utils.py
    â”œâ”€â”€ controllers.py
    â”œâ”€â”€ gesture_recognizer.py
    â”œâ”€â”€ hand_tracker.py
    â”œâ”€â”€ camera_diag.py
    â”œâ”€â”€ hand_model_demo.py
    â”‚
    â”œâ”€â”€ core/
    â”‚   â”œâ”€â”€ orchestrator.py
    â”‚   â””â”€â”€ __init__.py
    â”‚
    â”œâ”€â”€ pipeline/
    â”‚   â””â”€â”€ __init__.py
    â”‚
    â”œâ”€â”€ modes/
    â”‚   â”œâ”€â”€ base.py
    â”‚   â”œâ”€â”€ mouse_mode.py
    â”‚   â”œâ”€â”€ draw_mode.py
    â”‚   â”œâ”€â”€ demo_mode.py
    â”‚   â”œâ”€â”€ volume_mode.py
    â”‚   â””â”€â”€ __init__.py
    â”‚
    â”œâ”€â”€ tests/
    â”‚   â”œâ”€â”€ test_gesture_recognizer.py
    â”‚   â””â”€â”€ __init__.py
    â”‚
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ README.md

------------------------------------------------------------------------

## ğŸ” Module Explanation

### main.py

Entry point of the application. Launches the orchestrator and
initializes system flow.

### app.py

Handles application lifecycle and integrates tracker, GUI, and modes.

### gui.py

Responsible for visual overlays: - Drawing strokes - Displaying
feedback - Rendering system indicators

### constants.py

Contains tunable system parameters: - Gesture thresholds - Scaling
factors - Drawing configurations - Volume mapping ranges

### utils.py

Utility functions: - Distance calculations - Coordinate
transformations - Normalization helpers

### hand_tracker.py

Core hand tracking module: - Extracts hand landmarks - Computes pinch
distance - Provides structured landmark data

### gesture_recognizer.py

Implements geometric gesture logic: - Pinch detection - Finger state
recognition - Gesture mapping to interaction states

Includes unit tests in: `tests/test_gesture_recognizer.py`

### controllers.py

Abstracts OS-level interaction: - Mouse control - Click actions - Volume
control (Linux via amixer)

### core/orchestrator.py

Central system coordinator: - Connects all modules - Manages active
mode - Controls data flow

### modes/

**base.py** Defines abstract interface for interaction modes.

**mouse_mode.py** Maps hand motion to cursor movement and click
gestures.

**draw_mode.py** Implements air drawing with persistent stroke
rendering.

**volume_mode.py** Maps pinch distance to system volume (Linux
amixer-based).

**demo_mode.py** Visualization and testing mode.

------------------------------------------------------------------------

## ğŸ§  Extended Kalman Filter (EKF)

The EKF stabilizes 2D landmark coordinates by:

-   Modeling state transitions
-   Updating predictions with measurement correction
-   Reducing jitter
-   Ensuring smooth cursor motion

This significantly improves interaction quality and user experience.

------------------------------------------------------------------------

## âš™ Installation

### 1ï¸âƒ£ Clone Repository

    git clone <your-repo-url>
    cd hand-tracking-3d

### 2ï¸âƒ£ Create Virtual Environment

    python -m venv venv
    source venv/bin/activate

### 3ï¸âƒ£ Install Dependencies

    pip install -r requirements.txt

------------------------------------------------------------------------

## â–¶ Running the Project

    python main.py

Ensure camera permissions are enabled.

------------------------------------------------------------------------

## ğŸ’» Platform Support

  Feature          Windows   Linux   macOS
  ---------------- --------- ------- ---------
  Hand Tracking    âœ“         âœ“       âœ“
  Virtual Mouse    âœ“         âœ“       âœ“
  Air Drawing      âœ“         âœ“       âœ“
  Volume Control   Limited   âœ“       Limited

Volume control currently uses Linux `amixer`.

------------------------------------------------------------------------

## ğŸš€ Future Improvements

-   Cross-platform volume control
-   Multi-hand support
-   Deep learning gesture classification
-   Dynamic gesture sequences
-   GPU acceleration
-   Adaptive filtering models

------------------------------------------------------------------------

## ğŸ“š Academic Value

This project demonstrates:

-   Real-time computer vision systems
-   Landmark-based gesture recognition
-   Probabilistic filtering in HCI
-   Modular CV architecture design

Suitable for:

-   Computer Vision coursework
-   HCI research
-   Gesture-based system prototyping

------------------------------------------------------------------------

## ğŸ“„ License

Add your preferred license (MIT recommended).

------------------------------------------------------------------------

## ğŸ‘¤ Author

Developed as a modular computer vision and human--computer interaction
research project.
